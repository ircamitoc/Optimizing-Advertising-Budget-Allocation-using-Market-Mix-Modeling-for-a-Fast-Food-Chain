{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aim of the exercise is to measure effectiveness of each marketing channel and create a budget allocator for the Markerting Team \n",
    "# Hence we would be going for explanatory model and not a predictive model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6248\\478109950.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# For example, here's several helpful packages to load\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m \u001b[1;31m# linear algebra\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m \u001b[1;31m# data processing, CSV file I/O (e.g. pd.read_csv)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.arima_process import ArmaProcess\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "from math import ceil\n",
    "import datetime\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.metrics import max_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "from datetime import date,timedelta\n",
    "\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def week_of_month(dt):\n",
    "    \"\"\" Returns the week of the month for the specified date.\n",
    "    \"\"\"\n",
    "\n",
    "    first_day = dt.replace(day=1)\n",
    "\n",
    "    dom = dt.day\n",
    "    adjusted_dom = dom + first_day.weekday()\n",
    "\n",
    "    return int(ceil(adjusted_dom/7.0))\n",
    "\n",
    "# Decomposition\n",
    "def decompose(df_col,period,model):\n",
    "    decomposition = sm.tsa.seasonal_decompose(df_col,period =12,model=model) \n",
    "    figure2 = decomposition.plot()\n",
    "    figure(figsize=(16, 12), dpi=80)\n",
    "    plt.show()\n",
    "\n",
    "# Adfuller Test\n",
    "def adftest(df_col):\n",
    "    result = adfuller(df_col)\n",
    "    print(f'ADF Statistic: {result[0]}')\n",
    "    print(f'p-value: {result[1]}')\n",
    "    print(f'Critical Values:')\n",
    "    for key,val in result[4].items():\n",
    "        print(f'{key} {val}')\n",
    "\n",
    "# Plot ACF and PACF\n",
    "def plot_apacf(df_col,lags):\n",
    "    plot_acf(df_col, lags=lags)\n",
    "    plt.show()\n",
    "    plot_pacf(df_col,lags=lags)\n",
    "    plt.show()\n",
    "    \n",
    "# Check VIF\n",
    "def checkVIF(df,cols):\n",
    "    vif_data = pd.DataFrame()\n",
    "    X = df[cols]\n",
    "    vif_data[\"feature\"] = X.columns\n",
    "  \n",
    "    # calculating VIF for each feature\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(len(X.columns))]\n",
    "    return vif_data\n",
    "\n",
    "## Doing Log Transformations\n",
    "def logTransform(df,cols):\n",
    "    temp = df.copy()\n",
    "    arr = []\n",
    "    for j in cols:\n",
    "        temp[f'ln_{j}'] = np.log(temp[j])\n",
    "        arr.append(f'ln_{j}')\n",
    "    return(temp,arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a simple Linear regression \n",
    "# Input : Dataframe, Dependent Var, Independent Var, True/False for only positive Coeff, True/False for Plots\n",
    "def LRfit(df,dv,iv,ng,plot,printstats):\n",
    "    tt = df[df[dv].isna()==False]\n",
    "    reg_nnls = LinearRegression(positive=ng)\n",
    "\n",
    "    X = tt[iv]\n",
    "    y = tt[dv]\n",
    "\n",
    "    reg_nnls2 = reg_nnls.fit(X,y)\n",
    "\n",
    "    y_pred = reg_nnls2.predict(X)\n",
    "    \n",
    "    vif = checkVIF(X,iv)\n",
    "    \n",
    "    \n",
    "\n",
    "    run_year = tt['Date'].min()\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y,y_pred))\n",
    "    nmrse1 = rmse/y.std()\n",
    "    nmrse2 = rmse/(y.max() - y.min())\n",
    "    mae = mean_absolute_error(y,y_pred)\n",
    "    mape = mean_absolute_percentage_error(y,y_pred)\n",
    "    \n",
    "\n",
    "    coeff_arr = []\n",
    "\n",
    "    for q in reg_nnls2.coef_: \n",
    "        coeff_arr = np.insert(coeff_arr,len(coeff_arr),round(q,4))\n",
    "    inter = reg_nnls2.intercept_\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    \n",
    "    if printstats ==True:\n",
    "        print(vif)\n",
    "        print(run_year)\n",
    "        print(reg_nnls2.intercept_)\n",
    "        print(f'Coeff : {coeff_arr}')\n",
    "        print(f\"R2 : {(r2)}\")\n",
    "        print(f\"RMSE : {rmse}\")\n",
    "        print(f\"NMRSE1 : {nmrse1}\")\n",
    "        print(f\"NMRSE2 : {nmrse2}\")\n",
    "        print(f\"MAE : {(mae)}\")\n",
    "        print(f\"MAPE : {(mape)}\")\n",
    "\n",
    "    if plot == True:\n",
    "        sns.lineplot(data=tt,x=range(len(X)),y=dv,label='1')\n",
    "        sns.lineplot(x=range(len(y_pred)),y=y_pred,label='2')\n",
    "\n",
    "    return(y_pred,run_year,dv,iv,r2,rmse,nmrse1,nmrse2,mae,mape,inter,coeff_arr,vif)\n",
    "\n",
    "\n",
    "def convert_lr_fit_to_df(df, dv, iv):\n",
    "    return pd.DataFrame([LRfit(df,dv,iv)], columns=['model_run_TF','DV','IV','R2','RMSE','NMRSE1','NMRSE2','MAE','MAPE','Intercept','Coeff','VIF'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a simple Ridge regression \n",
    "def RidgeFit(df,dv,iv,ng,st,norm,alph,plot):\n",
    "    tt = df[df[dv].isna()==False]\n",
    "    reg = linear_model.Ridge(alpha=alph,positive=ng,normalize=norm)\n",
    "\n",
    "    X = tt[iv]\n",
    "    y = tt[dv]\n",
    "\n",
    "    reg2 = reg.fit(X,y)\n",
    "\n",
    "    y_pred = reg2.predict(X)\n",
    "    coeff = reg2.coef_\n",
    "    \n",
    "    inter= reg2.intercept_\n",
    "\n",
    "\n",
    "    coeff_arr = []\n",
    "\n",
    "    for q in coeff: \n",
    "        coeff_arr = np.insert(coeff_arr,len(coeff_arr),round(q,4))\n",
    "\n",
    "    run_year = tt['Date'].min()\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y,y_pred))\n",
    "    nmrse1 = rmse/y.std()\n",
    "    nmrse2 = rmse/(y.max() - y.min())\n",
    "    mae = mean_absolute_error(y,y_pred)\n",
    "    mape = mean_absolute_percentage_error(y,y_pred)\n",
    "\n",
    "    vif = checkVIF(X,iv)\n",
    "    \n",
    "\n",
    "    if plot == True:\n",
    "        sns.lineplot(data=tt,x=range(len(X)),y=dv,label='1')\n",
    "        sns.lineplot(x=range(len(y_pred)),y=y_pred,label='2')\n",
    "        print(vif)\n",
    "        print(f'Intercept : {inter}')\n",
    "        print(f'Coeff : {coeff_arr}')\n",
    "        print(f'R2 : {r2}')\n",
    "        print(f'RMSE : {rmse}')\n",
    "        print(f'MAE : {mae}')\n",
    "        print(f'MAPE : {mape}')\n",
    "\n",
    "    return(st,y_pred,run_year,dv,iv,r2,rmse,nmrse1,nmrse2,mae,mape,inter,coeff_arr,vif)\n",
    "\n",
    "def convert_ridge_fit_to_df(df, dv, iv,ng,st,norm,alph):\n",
    "    return pd.DataFrame([RidgeFit(df,dv,iv,ng,st,norm,alph,False)], columns=['base iv','y_pred','model_run_TF','DV','IV','R2','RMSE','NMRSE1','NMRSE2','MAE','MAPE','intercept','Coeff','VIF'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Subset according to days\n",
    "def dfTFdays(df,days):\n",
    "    return(df[df['Date']>=[date.today()- timedelta(days=days)]*len(df)])\n",
    "\n",
    "def spliceTF(df,days,enddt):\n",
    "     return(df[(df['Date']<=enddt) & (df['Date']>=[pd.to_datetime(enddt)- timedelta(days=days)]*len(df))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read input file\n",
    "data = pd.read_csv('Burger_Sales.csv')\n",
    "print(f'Lenght of Data Frame : {len(data)}')\n",
    "print(f'Minimum Date : {data[data.columns[0]].min()}')\n",
    "print(f'Minimum Date : {data[data.columns[0]].max()}')\n",
    "print(f'Columns : {data.columns}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = data_sel[['burger_sales', 'Instagram_Cost', 'Bing_Cost', 'Facebook_Cost',\n",
    "       'Google_Cost', 'Pinterest_Cost', 'Tiktok Cost']].corr()\n",
    "\n",
    "sns.heatmap(corr, \n",
    "        xticklabels=corr.columns,\n",
    "        yticklabels=corr.columns)\n",
    "\n",
    "# It seems our dataset has a lot of correlation in between the spends \n",
    "# Note: Marketing spends are generally increased/decreased across channels together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall Burger Sales Time Series\n",
    "plt.plot(data['burger_sales'])\n",
    "plt.show()\n",
    "\n",
    "# Q-Q Plot : To check for normality\n",
    "sm.qqplot(data['burger_sales'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(data['burger_sales'])\n",
    "# Two different distribution of Sales ; This might be due to new marketing channels coming into play  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Considering the time before 2021\n",
    "date_cond = data['Date'] < '2021-01-09'\n",
    "plt.plot(data[date_cond][:]['burger_sales'])\n",
    "plt.show()\n",
    "\n",
    "sns.kdeplot(data[date_cond]['burger_sales'])\n",
    "plt.show()\n",
    "\n",
    "# Q-Q Plot : To check for normality\n",
    "sm.qqplot(data[date_cond]['burger_sales'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time period after 2021 \n",
    "# Let us use this more recent data to model the relationship between sales and marketing spends\n",
    "\n",
    "date_cond = data['Date'] > '2021-01-08'\n",
    "plt.plot(data[date_cond][:]['burger_sales'])\n",
    "plt.show()\n",
    "\n",
    "sns.kdeplot(data[date_cond]['burger_sales'])\n",
    "plt.show()\n",
    "\n",
    "# Q-Q Plot : To check for normality\n",
    "sm.qqplot(data[date_cond]['burger_sales'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sel = data[date_cond]\n",
    "decompose(data_sel['burger_sales'],12,'additive')\n",
    "decompose(data_sel['burger_sales'],12,'multiplicative')\n",
    "\n",
    "# Seems like a multiplicative model would be better as the residuals are mode stable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_apacf(data_sel['burger_sales'],20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check for Multicollinearity \n",
    "\n",
    "checkVIF(data_sel,['burger_sales', 'Instagram_Cost', 'Bing_Cost', 'Facebook_Cost','Google_Cost', 'Pinterest_Cost', 'Tiktok Cost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing 0 by 0.01 in any spends , so that a log transformation can be taken\n",
    "for q in data_sel.columns[1:]:\n",
    "    print(q)\n",
    "    data_sel[q] = np.where(data_sel[q]==0,0.01,data_sel[q])\n",
    "    data_sel[f'ln_{q}'] = np.log(data_sel[q])\n",
    "    \n",
    "\n",
    "# We will create some seasonality features eg : year, month, day, dayofweek, weekofmonth\n",
    "\n",
    "data_sel['Date'] = pd.to_datetime(data_sel['Date'])\n",
    "data_sel['year'] = data_sel['Date'].dt.year\n",
    "data_sel['month'] = data_sel['Date'].dt.month\n",
    "data_sel['day'] = data_sel['Date'].dt.day\n",
    "data_sel['dayofWeek'] = data_sel['Date'].dt.dayofweek\n",
    "data_sel['dayofWeek']  = data_sel['dayofWeek']  + 1\n",
    "data_sel['weekOfMonth'] = data_sel['Date'].apply(lambda x: week_of_month(x))\n",
    "data_sel['weekofYear'] = data_sel.apply(lambda x: datetime.date(x.year, x.month, x.day).isocalendar()[1], axis=1)\n",
    "\n",
    "\n",
    "data_sel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data_sel[:]['ln_burger_sales'])\n",
    "plt.show()\n",
    "\n",
    "sns.kdeplot(data_sel['ln_burger_sales'])\n",
    "plt.show()\n",
    "\n",
    "# Q-Q Plot : To check for normality\n",
    "sm.qqplot(data_sel['burger_sales'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check for Multicollinearity \n",
    "\n",
    "checkVIF(data_sel,['burger_sales', 'Instagram_Cost', 'Bing_Cost', 'Facebook_Cost','Google_Cost', 'Pinterest_Cost', 'Tiktok Cost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkVIF(data_sel,['ln_burger_sales', 'ln_Instagram_Cost', 'ln_Bing_Cost', 'ln_Facebook_Cost','ln_Google_Cost', 'ln_Pinterest_Cost', 'ln_Tiktok Cost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkVIF(data_sel,['ln_burger_sales', 'Instagram_Cost', 'Bing_Cost', 'Facebook_Cost','Google_Cost', 'Pinterest_Cost', 'Tiktok Cost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkVIF(data_sel,['burger_sales','month','dayofWeek','weekOfMonth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will go with 2 models. \n",
    "# First is a base model without spends \n",
    "# Second Model will include the base sales and the Marketing Spends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrl_arr = ['month','dayofWeek','weekOfMonth']\n",
    "iv_arr = ['Instagram_Cost', 'Bing_Cost', 'Facebook_Cost','Google_Cost', 'Pinterest_Cost', 'Tiktok Cost']\n",
    "iv_ln_arr = ['ln_Instagram_Cost', 'ln_Bing_Cost', 'ln_Facebook_Cost','ln_Google_Cost', 'ln_Pinterest_Cost', 'ln_Tiktok Cost']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred,run_year,dv,iv,r2,rmse,nmrse1,nmrse2,mae,mape,inter,coeff_arr,vif = LRfit(data_sel,'ln_burger_sales',ctrl_arr,False,True,False)\n",
    "data_sel['base_ln'] = y_pred\n",
    "data_sel['base_y'] = np.exp(y_pred)\n",
    "\n",
    "base_model_intercept = inter\n",
    "base_model_coeffs = coeff_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "st,y_pred,run_year,dv,iv,r2,rmse,nmrse1,nmrse2,mae,mape,inter,coeff_arr,vif = RidgeFit(data_sel,'ln_burger_sales',np.append(['base_ln'],iv_ln_arr),True,'test',False,1,True)\n",
    "\n",
    "# We cannot have 0 as coefficient for any of the channels as it means there is 0 contributio from that channel \n",
    "# Lets try for different Time periods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will iterate every 15 days and fit a sales, ln_sales with two different independent variables \n",
    "# our objective is to find a time period for each we get a positive coefficient for each channel \n",
    "# each row at the end is a model fitted with different metrics\n",
    "\n",
    "ChampChallenger = pd.DataFrame(columns=['base iv','model_run_TF','DV','IV','R2','RMSE','NMRSE1','NMRSE2','MAE','MAPE','intercept','Coeff','VIF'])\n",
    "testcp = data_sel.copy()\n",
    "\n",
    "## Iterating over 1 to 3 years, with 1 month increment\n",
    "for p in range(180,1080,15):\n",
    "    \n",
    "    df = spliceTF(testcp,p,'2022-05-31')\n",
    "    df,arr1 = logTransform(df,['burger_sales'])\n",
    "    df,arr1  = logTransform(df,iv_arr)\n",
    "\n",
    "    y_pred,run_year,dv,iv,r2,rmse,nmrse1,nmrse2,mae,mape,inter,coeff_arr,vif = LRfit(data_sel,'ln_burger_sales',ctrl_arr,False,False,False)\n",
    "    data_sel['base_ln'] = y_pred\n",
    "    data_sel['base_y'] = np.exp(y_pred)\n",
    "\n",
    "    iv_arr = ['base_y','Instagram_Cost', 'Bing_Cost', 'Facebook_Cost','Google_Cost', 'Pinterest_Cost', 'Tiktok Cost']\n",
    "    iv_ln_arr = ['base_ln','ln_Instagram_Cost', 'ln_Bing_Cost', 'ln_Facebook_Cost','ln_Google_Cost', 'ln_Pinterest_Cost', 'ln_Tiktok Cost']\n",
    "\n",
    "   \n",
    "    dvt = ['burger_sales','ln_burger_sales']\n",
    "\n",
    "    for ivt in [iv_ln_arr]:\n",
    "        for dvtp in dvt:\n",
    "            if (convert_ridge_fit_to_df(df=df, dv=dvtp, iv=ivt,ng=True,st=f' na',norm=False,alph=0.9).iloc[0]['Coeff'].min()<=0):\n",
    "                continue\n",
    "            else:\n",
    "                ChampChallenger = ChampChallenger.append(convert_ridge_fit_to_df(df=df, dv=dvtp, iv=ivt,ng=True,st=f'alpha:{p}',norm=False,alph=0.9))\n",
    "\n",
    "ChampChallenger = ChampChallenger.sort_values(by='MAPE',ascending=True)\n",
    "\n",
    "\n",
    "ChampChallenger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will take the top row as model \n",
    "from sklearn import linear_model\n",
    "\n",
    "testcp = data_sel.copy()\n",
    "testcp = spliceTF(testcp,195,'2022-05-31')\n",
    "\n",
    "y_pred,run_year,dv,iv,r2,rmse,nmrse1,nmrse2,mae,mape,inter,coeff_arr,vif = LRfit(testcp,'ln_burger_sales',ctrl_arr,False,False,True)\n",
    "testcp['base_ln'] = y_pred\n",
    "testcp['base_y'] = np.exp(y_pred)\n",
    "st,y_pred,run_year,dv,iv,r2,rmse,nmrse1,nmrse2,mae,mape,inter,coeff_arr,vif = RidgeFit(testcp,'ln_burger_sales',iv_ln_arr,True,'test',False,1,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Our final model : \n",
    "\n",
    "1. Control Model : \n",
    "Intercept : 9.29974879006081\n",
    "Coeff : [-0.0325 -0.0513  0.0087]\n",
    "\n",
    "2. MMM Model : \n",
    "Intercept : 3.379554614274598\n",
    "Coeff : [0.0692 0.0043 0.0013 0.1646 0.2793 0.0289 0.002 ]\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing final model coeffs and intercepts\n",
    "base_intecept = 9.29974879006081\n",
    "base_coeffs = [-0.0325, -0.0513,  0.0087]\n",
    "\n",
    "mmm_intercept = 3.379554614274598\n",
    "mmm_coeff = [0.0692, 0.0043, 0.0013, 0.1646, 0.2793, 0.0289, 0.002 ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating channel contributions and ROAS\n",
    "df = testcp.copy()\n",
    "df.columns\n",
    "\n",
    "coeffs = mmm_coeff\n",
    "df['pred_ln'] = y_pred\n",
    "df['pred_y'] = np.exp(df['pred_ln'])\n",
    "\n",
    "\n",
    "df['baseline'] = np.exp(mmm_intercept)*(df['base_y']**coeffs[0])\n",
    "df['multiplicative_pred']= df['baseline']* df['Instagram_Cost']**(coeffs[1]) * (df['Bing_Cost']**(coeffs[2])) * (df['Facebook_Cost']**(coeffs[3])) * (df['Google_Cost']**(coeffs[4])) * (df['Pinterest_Cost']**(coeffs[5])) * (df['Tiktok Cost']**(coeffs[6]))\n",
    "\n",
    "# Calculating Contributions\n",
    "df['Instagram_Contri'] = df['multiplicative_pred']*(1-1/df['Instagram_Cost']**(coeffs[1]))\n",
    "df['Bing_Contri'] = df['multiplicative_pred']*(1-1/df['Bing_Cost']**(coeffs[2]))\n",
    "df['Facebook_Contri'] = df['multiplicative_pred']*(1-1/df['Facebook_Cost']**(coeffs[3]))\n",
    "df['Google_Contri'] = df['multiplicative_pred']*(1-1/df['Google_Cost']**(coeffs[4]))\n",
    "df['Pinterest_Contri'] = df['multiplicative_pred']*(1-1/df['Pinterest_Cost']**(coeffs[5]))\n",
    "df['Tiktok_Contri'] = df['multiplicative_pred']*(1-1/df['Tiktok Cost']**(coeffs[6]))\n",
    "\n",
    "df['Total_Contri'] = df['Instagram_Contri'] + df['Bing_Contri'] + df['Facebook_Contri'] + df['Google_Contri'] + df['Pinterest_Contri'] + df['Tiktok_Contri']\n",
    "df['Actual_Contri'] = df['multiplicative_pred'] - df['baseline']\n",
    "\n",
    "# Adjusting the Contributions\n",
    "df['Instagram_Adj_Contri'] = df['Instagram_Contri']*(1-(df['Total_Contri']-df['Actual_Contri'])/(df['Total_Contri']))\n",
    "df['Bing_Adj_Contri'] = df['Bing_Contri']*(1-(df['Total_Contri']-df['Actual_Contri'])/(df['Total_Contri']))\n",
    "df['Facebook_Adj_Contri'] = df['Facebook_Contri']*(1-(df['Total_Contri']-df['Actual_Contri'])/(df['Total_Contri']))\n",
    "df['Google_Adj_Contri'] = df['Google_Contri']*(1-(df['Total_Contri']-df['Actual_Contri'])/(df['Total_Contri']))\n",
    "df['Pinterest_Adj_Contri'] = df['Pinterest_Contri']*(1-(df['Total_Contri']-df['Actual_Contri'])/(df['Total_Contri']))\n",
    "df['Tiktok_Adj_Contri'] = df['Tiktok_Contri']*(1-(df['Total_Contri']-df['Actual_Contri'])/(df['Total_Contri']))\n",
    "\n",
    "\n",
    "df['Test_Contri'] = df['baseline'] + df['Instagram_Adj_Contri'] + df['Bing_Adj_Contri']  + df['Facebook_Adj_Contri']  + df['Google_Adj_Contri'] + df['Pinterest_Adj_Contri'] + df['Tiktok_Adj_Contri']\n",
    "\n",
    "# ROAS = Adjusted Contribution / Cost \n",
    "df['Instagram ROAS'] = df['Instagram_Adj_Contri'] / df['Instagram_Cost']\n",
    "df['Bing ROAS'] = df['Bing_Adj_Contri'] / df['Bing_Cost']\n",
    "df['Facebook ROAS'] = df['Facebook_Adj_Contri'] / df['Facebook_Cost']\n",
    "df['Google ROAS'] = df['Google_Adj_Contri'] / df['Google_Cost']\n",
    "df['Pinterest ROAS'] = df['Pinterest_Adj_Contri'] / df['Pinterest_Cost']\n",
    "df['Tiktok ROAS'] = df['Tiktok_Adj_Contri'] / df['Tiktok Cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contribution Charts\n",
    "sns.scatterplot(data=df,x='Instagram_Cost',y='Instagram_Adj_Contri',label='Instagram')\n",
    "sns.scatterplot(data=df,x='Bing_Cost',y='Bing_Adj_Contri',label='Bing')\n",
    "sns.scatterplot(data=df,x='Tiktok Cost',y='Tiktok_Adj_Contri',label='Tiktok')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=df,x='Facebook_Cost',y='Facebook_Adj_Contri',label='Facebook')\n",
    "sns.scatterplot(data=df,x='Google_Cost',y='Google_Adj_Contri',label='Google')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=df,x='Facebook_Cost',y='Facebook_Adj_Contri',label='Facebook')\n",
    "sns.scatterplot(data=df,x='Google_Cost',y='Google_Adj_Contri',label='Google')\n",
    "\n",
    "sns.scatterplot(data=df,x='Instagram_Cost',y='Instagram_Adj_Contri',label='Instagram')\n",
    "sns.scatterplot(data=df,x='Bing_Cost',y='Bing_Adj_Contri',label='Bing')\n",
    "sns.scatterplot(data=df,x='Tiktok Cost',y='Tiktok_Adj_Contri',label='Tiktok')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=df,x='Pinterest_Cost',y='Pinterest_Adj_Contri',label='Pinterest')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0a54084e6b208ee8d1ce3989ffc20924477a5f55f5a43e22e699a6741623861e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
